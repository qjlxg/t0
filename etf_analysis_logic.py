import os
import pandas as pd
import glob
from datetime import datetime, timedelta
import multiprocessing

# ==========================================
# æˆ˜æ³•ï¼šã€å…¨åŠŸèƒ½Â·æ•°æ®å¯¹é½ç»ˆæç‰ˆã€‘
# 1. è‡ªåŠ¨ä¿®å¤ all_valid_data.csv ä»£ç åŒ¹é…é—®é¢˜
# 2. ä¸¥æ ¼æ‰§è¡Œ 2% æº¢ä»·ç†”æ–­ï¼Œå‰”é™¤æ·±å‘æ ‡çš„
# 3. å®Œæ•´ä¿ç•™å…¨é‡/3å¹´è¿è·Œç»Ÿè®¡é€»è¾‘
# 4. è‡ªåŠ¨æŒ‰å¹´æœˆå½’æ¡£ç»“æœ
# ==========================================

def get_stats(df):
    stats = []
    for d in [2, 3, 4, 5]:
        target_idx = df[df['down_count'] == d].index + 1
        target_idx = [i for i in target_idx if i < len(df)]
        if not target_idx:
            stats.extend([0.0, 0.0])
            continue
        changes = (df.iloc[target_idx]['æ”¶ç›˜'].values - df.iloc[[i-1 for i in target_idx]]['æ”¶ç›˜'].values) / df.iloc[[i-1 for i in target_idx]]['æ”¶ç›˜'].values * 100
        stats.extend([round(changes.mean(), 2), round((changes > 0).mean() * 100, 2)])
    return stats

def analyze_single_file(file_path, etf_names):
    try:
        df = pd.read_csv(file_path)
        if len(df) < 60: return None
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        symbol = os.path.basename(file_path).split('.')[0].zfill(6)
        
        # åŒ¹é…åç§°
        name = etf_names.get(symbol, "æœªçŸ¥")

        # 1. è¿è·Œè®¡ç®—
        df['is_down'] = df['æ”¶ç›˜'].diff() < 0
        counts, cur = [], 0
        for val in df['is_down']:
            if val: cur += 1
            else: cur = 0
            counts.append(cur)
        df['down_count'] = counts
        
        # 2. è¶‹åŠ¿ä¸åç¦»åº¦
        ma_period = 250 if len(df) >= 250 else 60
        df['ma_trend'] = df['æ”¶ç›˜'].rolling(window=ma_period).mean()
        curr_price = df['æ”¶ç›˜'].iloc[-1]
        is_bull = curr_price > df['ma_trend'].iloc[-1]
        df['ma20'] = df['æ”¶ç›˜'].rolling(20).mean()
        bias20 = ((curr_price - df['ma20'].iloc[-1]) / df['ma20'].iloc[-1]) * 100
        
        # 3. è¯„åˆ†åˆ†çº§
        curr_down = counts[-1]
        rating, prio = "è¿‡æ»¤", 0
        if curr_down >= 2:
            if is_bull:
                score = curr_down + (2 if bias20 < -3 else 0)
                rating, prio = f"ğŸ”´é¡ºåŠ¿ {'â­'*score}", 100 + score
            elif curr_down >= 4 or bias20 < -8:
                rating, prio = f"ğŸ”µåå¼¹ {'âš¡'*curr_down}", 50 + curr_down
        
        if rating == "è¿‡æ»¤": return None

        # 4. è·å–å†å²ç»Ÿè®¡
        full_stats = get_stats(df)
        three_years_ago = datetime.now() - timedelta(days=1095)
        df_3y = df[df['æ—¥æœŸ'] >= three_years_ago].copy()
        three_year_stats = get_stats(df_3y) if not df_3y.empty else [0.0]*8
        
        base_info = [symbol, name, rating, "å¤šå¤´" if is_bull else "ç©ºå¤´", round(bias20, 2), curr_down]
        return (base_info + full_stats + three_year_stats, prio, bias20)
    except: return None

def main():
    # 1. åŠ è½½ ETF åç§°å­—å…¸ (å¼ºåˆ¶ 6 ä½å¯¹é½)
    etf_names = {}
    name_file = 'ETFåˆ—è¡¨.xlsx'
    if os.path.exists(name_file):
        try:
            m_df = pd.read_excel(name_file, dtype={0: str})
            etf_names = dict(zip(m_df.iloc[:,0].str.zfill(6), m_df.iloc[:,1]))
        except:
            try:
                m_df = pd.read_csv(name_file, dtype={0: str})
                etf_names = dict(zip(m_df.iloc[:,0].str.zfill(6), m_df.iloc[:,1]))
            except: pass

    # 2. åŠ è½½æº¢ä»·æ•°æ®å¹¶ä¿®å¤æ ¼å¼
    premium_dict = {}
    prem_file = 'all_valid_data.csv'
    if os.path.exists(prem_file):
        try:
            # è‡ªåŠ¨è¯†åˆ«åˆ†éš”ç¬¦å¹¶æ¸…ç†æ•°æ®
            av_df = pd.read_csv(prem_file, sep=None, engine='python')
            av_df.columns = [c.strip() for c in av_df.columns]
            
            # å…³é”®ï¼šä¿®å¤ä»£ç å­—æ®µï¼Œè½¬ä¸º 6 ä½å­—ç¬¦ä¸²
            av_df['ä»£ç '] = av_df['ä»£ç '].astype(str).str.replace('.0', '', regex=False).str.zfill(6)
            
            # å…³é”®ï¼šä¿®å¤æº¢ä»·ç‡å­—æ®µï¼Œè½¬ä¸ºæµ®ç‚¹æ•°
            av_df['æº¢ä»·ç‡_val'] = av_df['æº¢ä»·ç‡'].astype(str).str.replace('%', '').replace('nan', '0').astype(float)
            
            premium_dict = av_df.set_index('ä»£ç ')[['æº¢ä»·ç‡', 'ä¼°ç®—å‡€å€¼', 'æº¢ä»·ç‡_val']].to_dict('index')
            print(f"æˆåŠŸè½½å…¥ {len(premium_dict)} æ¡å®æ—¶æº¢ä»·å‚è€ƒã€‚")
        except Exception as e:
            print(f"æº¢ä»·æ–‡ä»¶åŒ¹é…å¤±è´¥: {e}")

    # 3. å¹¶è¡Œè®¡ç®—
    csv_files = glob.glob('fund_data/*.csv')
    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:
        raw_results = pool.starmap(analyze_single_file, [(f, etf_names) for f in csv_files])

    valid_results = [r[0] for r in raw_results if r is not None]
    if not valid_results:
        print("ä»Šæ—¥æ— ç¬¦åˆæ¡ä»¶ä¿¡å·ã€‚")
        return

    # 4. ç”Ÿæˆ DataFrame å¹¶æ‰§è¡Œå®æ—¶è¿‡æ»¤
    cols = ['ä»£ç ', 'åç§°', 'æ“ä½œå»ºè®®', 'å¤§è¶‹åŠ¿', 'åç¦»åº¦%', 'å½“å‰è¿è·Œ', 
            'å…¨2å‡æ¶¨', 'å…¨2èƒœç‡%', 'å…¨3å‡æ¶¨', 'å…¨3èƒœç‡%', 'å…¨4å‡æ¶¨', 'å…¨4èƒœç‡%', 'å…¨5å‡æ¶¨', 'å…¨5èƒœç‡%',
            '3å¹´2å‡æ¶¨', '3å¹´2èƒœç‡%', '3å¹´3å‡æ¶¨', '3å¹´3èƒœç‡%', '3å¹´4å‡æ¶¨', '3å¹´4èƒœç‡%', '3å¹´5å‡æ¶¨', '3å¹´5èƒœç‡%']
    
    res_df = pd.DataFrame(valid_results, columns=cols)

    def apply_premium_safe(row):
        code = row['ä»£ç ']
        if code in premium_dict:
            p = premium_dict[code]
            # æ‰§è¡Œ 2% æº¢ä»·ç†”æ–­
            if p['æº¢ä»·ç‡_val'] > 2.0: return None, None, True
            return p['æº¢ä»·ç‡'], p['ä¼°ç®—å‡€å€¼'], False
        return "æœªçŸ¥", "æœªçŸ¥", False

    res_df[['å®æ—¶æº¢ä»·ç‡', 'å‚è€ƒå‡€å€¼', 'is_filtered']] = res_df.apply(lambda r: pd.Series(apply_premium_safe(r)), axis=1)
    
    # å‰”é™¤é«˜æº¢ä»·æ ‡çš„
    final_df = res_df[res_df['is_filtered'] == False].drop(columns=['is_filtered']).copy()

    # 5. æ’åºä¸è¯†åˆ«â€œä»Šæ—¥ä¹‹æ˜Ÿâ€
    prio_map = {r[0][0]: r[1] for r in raw_results if r is not None}
    bias_map = {r[0][0]: r[2] for r in raw_results if r is not None}
    final_df['prio'] = final_df['ä»£ç '].map(prio_map)
    final_df['bias_val'] = final_df['ä»£ç '].map(bias_map)
    
    final_df = final_df.sort_values(['prio', 'bias_val'], ascending=[False, True])
    if not final_df.empty:
        final_df.iloc[0, 2] = "ğŸ‘‘ä»Šæ—¥ä¹‹æ˜Ÿ " + final_df.iloc[0, 2]
    
    final_df = final_df.drop(columns=['prio', 'bias_val'])

    # 6. å½’æ¡£
    now = datetime.now()
    month_dir = now.strftime('%Y%m')
    if not os.path.exists(month_dir): os.makedirs(month_dir)
    save_path = os.path.join(month_dir, f"etf_final_strategy_{now.strftime('%Y%m%d_%H%M%S')}.csv")
    final_df.to_csv(save_path, index=False, encoding='utf_8_sig')
    print(f"å¤„ç†å®Œæˆï¼å·²è‡ªåŠ¨å‰”é™¤é«˜æº¢ä»·é£é™©é¡¹ã€‚æœ€ç»ˆåå•ä¿å­˜è‡³: {save_path}")

if __name__ == '__main__':
    main()
