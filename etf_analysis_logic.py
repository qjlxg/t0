import os
import pandas as pd
import glob
from datetime import datetime, timedelta
import multiprocessing

# ==========================================
# æˆ˜æ³•ï¼šã€å…¨åŠŸèƒ½Â·æº¢ä»·ç†”æ–­ç‰ˆã€‘
# ä¿®æ­£ï¼šé’ˆå¯¹ all_valid_data.csv æ ¼å¼è¿›è¡Œç²¾å‡†åŒ¹é…
# ==========================================

def get_stats(df):
    stats = []
    for d in [2, 3, 4, 5]:
        target_idx = df[df['down_count'] == d].index + 1
        target_idx = [i for i in target_idx if i < len(df)]
        if not target_idx:
            stats.extend([0.0, 0.0])
            continue
        changes = (df.iloc[target_idx]['æ”¶ç›˜'].values - df.iloc[[i-1 for i in target_idx]]['æ”¶ç›˜'].values) / df.iloc[[i-1 for i in target_idx]]['æ”¶ç›˜'].values * 100
        stats.extend([round(changes.mean(), 2), round((changes > 0).mean() * 100, 2)])
    return stats

def analyze_single_file(file_path, etf_names):
    try:
        df = pd.read_csv(file_path)
        if len(df) < 60: return None
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        symbol = os.path.basename(file_path).split('.')[0].zfill(6)
        name = etf_names.get(symbol, "æœªçŸ¥")

        # 1. è¿è·Œ
        df['is_down'] = df['æ”¶ç›˜'].diff() < 0
        counts, cur = [], 0
        for val in df['is_down']:
            if val: cur += 1
            else: cur = 0
            counts.append(cur)
        df['down_count'] = counts
        
        # 2. è¶‹åŠ¿ä¸åç¦»
        ma_period = 250 if len(df) >= 250 else 60
        df['ma_trend'] = df['æ”¶ç›˜'].rolling(window=ma_period).mean()
        curr_price = df['æ”¶ç›˜'].iloc[-1]
        is_bull = curr_price > df['ma_trend'].iloc[-1]
        df['ma20'] = df['æ”¶ç›˜'].rolling(20).mean()
        bias20 = ((curr_price - df['ma20'].iloc[-1]) / df['ma20'].iloc[-1]) * 100
        
        # 3. è¯„åˆ†
        curr_down = counts[-1]
        rating, prio = "è¿‡æ»¤", 0
        if curr_down >= 2:
            if is_bull:
                score = curr_down + (2 if bias20 < -3 else 0)
                rating, prio = f"ğŸ”´é¡ºåŠ¿ {'â­'*score}", 100 + score
            elif curr_down >= 4 or bias20 < -8:
                rating, prio = f"ğŸ”µé€†åŠ¿æŠ¢åå¼¹ {'âš¡'*curr_down}", 50 + curr_down
        
        if rating == "è¿‡æ»¤": return None
        return ([symbol, name, rating, "å¤šå¤´" if is_bull else "ç©ºå¤´", round(bias20, 2), curr_down] + get_stats(df) + get_stats(df[df['æ—¥æœŸ'] >= datetime.now() - timedelta(days=1095)]), prio, bias20)
    except: return None

def main():
    # 1. åŠ è½½åç§° (æ”¯æŒ XLSX/CSV)
    etf_names = {}
    name_file = 'ETFåˆ—è¡¨.xlsx'
    if not os.path.exists(name_file): name_file = 'ETFåˆ—è¡¨.xlsx - Sheet1.csv'
    if os.path.exists(name_file):
        try:
            m_df = pd.read_excel(name_file, dtype={'è¯åˆ¸ä»£ç ': str}) if 'xlsx' in name_file else pd.read_csv(name_file, dtype={'è¯åˆ¸ä»£ç ': str})
            etf_names = dict(zip(m_df.iloc[:,0].str.zfill(6), m_df.iloc[:,1]))
        except: pass

    # 2. ç²¾å‡†åŒ¹é…æº¢ä»·æ•°æ®
    premium_dict = {}
    if os.path.exists('all_valid_data.csv'):
        try:
            # è‡ªåŠ¨å¤„ç†åˆ¶è¡¨ç¬¦åˆ†éš”æˆ–é€—å·åˆ†éš”
            av_df = pd.read_csv('all_valid_data.csv', sep=None, engine='python', dtype={'ä»£ç ': str})
            # å¤„ç†æº¢ä»·ç‡å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "3.89%" -> 3.89
            av_df['æº¢ä»·ç‡_val'] = av_df['æº¢ä»·ç‡'].astype(str).str.replace('%', '').replace('nan', '0').astype(float)
            premium_dict = av_df.set_index('ä»£ç ')[['æº¢ä»·ç‡', 'ä¼°ç®—å‡€å€¼', 'æº¢ä»·ç‡_val']].to_dict('index')
        except Exception as e: print(f"æº¢ä»·æ•°æ®è§£ææç¤º: {e}")

    # 3. å¹¶è¡Œåˆ†æ
    csv_files = glob.glob('fund_data/*.csv')
    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:
        raw_results = pool.starmap(analyze_single_file, [(f, etf_names) for f in csv_files])

    # 4. æ±‡æ€»ä¸è¿‡æ»¤
    valid_results = [r[0] for r in raw_results if r is not None]
    if not valid_results: return print("ä»Šæ—¥æ— ä¿¡å·")

    cols = ['ä»£ç ', 'åç§°', 'æ“ä½œå»ºè®®', 'å¤§è¶‹åŠ¿', 'åç¦»åº¦%', 'å½“å‰è¿è·Œ', 
            'å…¨2å‡æ¶¨', 'å…¨2èƒœç‡%', 'å…¨3å‡æ¶¨', 'å…¨3èƒœç‡%', 'å…¨4å‡æ¶¨', 'å…¨4èƒœç‡%', 'å…¨5å‡æ¶¨', 'å…¨5èƒœç‡%',
            '3å¹´2å‡æ¶¨', '3å¹´2èƒœç‡%', '3å¹´3å‡æ¶¨', '3å¹´3èƒœç‡%', '3å¹´4å‡æ¶¨', '3å¹´4èƒœç‡%', '3å¹´5å‡æ¶¨', '3å¹´5èƒœç‡%']
    res_df = pd.DataFrame(valid_results, columns=cols)

    # æº¢ä»·æ¯”å¯¹é€»è¾‘
    def get_prem_info(row):
        code = row['ä»£ç ']
        if code in premium_dict:
            p = premium_dict[code]
            if p['æº¢ä»·ç‡_val'] > 2.0: return None, None, True # ç†”æ–­è¿‡æ»¤
            return p['æº¢ä»·ç‡'], p['ä¼°ç®—å‡€å€¼'], False
        return "æœªçŸ¥", "æœªçŸ¥", False

    res_df[['å®æ—¶æº¢ä»·ç‡', 'å‚è€ƒå‡€å€¼', 'is_filtered']] = res_df.apply(lambda r: pd.Series(get_prem_info(r)), axis=1)
    final_df = res_df[res_df['is_filtered'] == False].drop(columns=['is_filtered']).copy()

    # 5. æ’åºä¸çš‡å† æ ‡è®°
    prio_map = {r[0][0]: r[1] for r in raw_results if r is not None}
    bias_map = {r[0][0]: r[2] for r in raw_results if r is not None}
    final_df['prio'] = final_df['ä»£ç '].map(prio_map)
    final_df['bias'] = final_df['ä»£ç '].map(bias_map)
    final_df = final_df.sort_values(['prio', 'bias'], ascending=[False, True])
    if not final_df.empty:
        final_df.iloc[0, 2] = "ğŸ‘‘ä»Šæ—¥ä¹‹æ˜Ÿ " + final_df.iloc[0, 2]

    # 6. ä¿å­˜å½’æ¡£
    final_df = final_df.drop(columns=['prio', 'bias'])
    month_dir = datetime.now().strftime('%Y%m')
    if not os.path.exists(month_dir): os.makedirs(month_dir)
    save_path = os.path.join(month_dir, f"etf_final_strategy_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
    final_df.to_csv(save_path, index=False, encoding='utf_8_sig')
    print(f"æˆåŠŸå½’æ¡£è‡³: {save_path} (å·²ç†”æ–­æº¢ä»·>2%çš„é£é™©æ ‡çš„)")

if __name__ == '__main__':
    main()
