import os
import pandas as pd
import glob
from datetime import datetime, timedelta
import multiprocessing

# ==========================================
# æˆ˜æ³•åç§°ï¼šã€è¿è·Œå›è°ƒÂ·æº¢ä»·é£æ§ç»ˆæç‰ˆã€‘
# æ ¸å¿ƒé€»è¾‘ï¼š
# 1. æˆ˜æ³•è§¦å‘ï¼šè¿è·Œ + è¶‹åŠ¿ + åç¦»åº¦ã€‚
# 2. æº¢ä»·ç†”æ–­ï¼šæ¯”å¯¹ all_valid_data.csvï¼Œå‰”é™¤æº¢ä»· > 2% çš„æ ‡çš„ã€‚
# 3. ç»“æœç²¾é€‰ï¼šåªè¾“å‡ºä½æº¢ä»·çš„é¡ºåŠ¿çº¢æ ‡å’Œé€†åŠ¿è“æ ‡ã€‚
# ==========================================

def get_stats(df):
    stats = []
    for d in [2, 3, 4, 5]:
        target_idx = df[df['down_count'] == d].index + 1
        target_idx = [i for i in target_idx if i < len(df)]
        if not target_idx:
            stats.extend([0.0, 0.0])
            continue
        changes = (df.iloc[target_idx]['æ”¶ç›˜'].values - df.iloc[[i-1 for i in target_idx]]['æ”¶ç›˜'].values) / df.iloc[[i-1 for i in target_idx]]['æ”¶ç›˜'].values * 100
        stats.extend([round(changes.mean(), 2), round((changes > 0).mean() * 100, 2)])
    return stats

def analyze_single_file(file_path, etf_names):
    try:
        df = pd.read_csv(file_path)
        if len(df) < 60: return None
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        symbol = os.path.basename(file_path).split('.')[0].zfill(6)
        name = etf_names.get(symbol, "æœªçŸ¥")

        # 1. è¿è·Œè®¡ç®—
        df['is_down'] = df['æ”¶ç›˜'].diff() < 0
        counts, cur = [], 0
        for val in df['is_down']:
            if val: cur += 1
            else: cur = 0
            counts.append(cur)
        df['down_count'] = counts
        
        # 2. è¶‹åŠ¿ä¸åç¦»åº¦
        ma_period = 250 if len(df) >= 250 else 60
        df['ma_trend'] = df['æ”¶ç›˜'].rolling(window=ma_period).mean()
        curr_price = df['æ”¶ç›˜'].iloc[-1]
        is_bull = curr_price > df['ma_trend'].iloc[-1]
        df['ma20'] = df['æ”¶ç›˜'].rolling(20).mean()
        bias20 = ((curr_price - df['ma20'].iloc[-1]) / df['ma20'].iloc[-1]) * 100
        
        # 3. è¯„åˆ†
        curr_down = counts[-1]
        rating, prio = "è¿‡æ»¤", 0
        if curr_down >= 2:
            if is_bull:
                score = curr_down + (2 if bias20 < -3 else 0)
                rating, prio = f"ğŸ”´é¡ºåŠ¿ {'â­'*score}", 100 + score
            elif curr_down >= 4 or bias20 < -8:
                rating, prio = f"ğŸ”µé€†åŠ¿æŠ¢åå¼¹ {'âš¡'*curr_down}", 50 + curr_down
        
        if rating == "è¿‡æ»¤": return None
        return ([symbol, name, rating, "å¤šå¤´" if is_bull else "ç©ºå¤´", round(bias20, 2), curr_down] + get_stats(df) + get_stats(df[df['æ—¥æœŸ'] >= datetime.now() - timedelta(days=1095)]), prio, bias20)
    except: return None

def main():
    # 1. åŠ è½½æº¢ä»·æ•°æ® (all_valid_data.csv)
    premium_data = {}
    if os.path.exists('all_valid_data.csv'):
        av_df = pd.read_csv('all_valid_data.csv', dtype={'ä»£ç ': str})
        # å°†æº¢ä»·ç‡å­—ç¬¦ä¸² "-0.13%" è½¬ä¸ºæµ®ç‚¹æ•° -0.13
        av_df['æº¢ä»·ç‡_num'] = av_df['æº¢ä»·ç‡'].str.replace('%', '').astype(float)
        premium_data = av_df.set_index('ä»£ç ')[['æº¢ä»·ç‡', 'ä¼°ç®—å‡€å€¼', 'æº¢ä»·ç‡_num']].to_dict('index')

    # 2. åŠ è½½åç§°
    etf_names = {}
    if os.path.exists('ETFåˆ—è¡¨.xlsx - Sheet1.csv'):
        m_df = pd.read_csv('ETFåˆ—è¡¨.xlsx - Sheet1.csv', dtype={'è¯åˆ¸ä»£ç ': str})
        etf_names = dict(zip(m_df['è¯åˆ¸ä»£ç '].str.zfill(6), m_df['è¯åˆ¸ç®€ç§°']))

    # 3. åˆ†æ
    csv_files = glob.glob('fund_data/*.csv')
    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:
        raw_results = pool.starmap(analyze_single_file, [(f, etf_names) for f in csv_files])

    valid_results = [r[0] for r in raw_results if r is not None]
    prios = [r[1] for r in raw_results if r is not None]
    biases = [r[2] for r in raw_results if r is not None]
    
    if not valid_results: return print("ä»Šæ—¥æ— ä¿¡å·ã€‚")

    cols = ['ä»£ç ', 'åç§°', 'æ“ä½œå»ºè®®', 'å¤§è¶‹åŠ¿', 'åç¦»åº¦%', 'å½“å‰è¿è·Œ', 
            'å…¨2å‡æ¶¨', 'å…¨2èƒœç‡%', 'å…¨3å‡æ¶¨', 'å…¨3èƒœç‡%', 'å…¨4å‡æ¶¨', 'å…¨4èƒœç‡%', 'å…¨5å‡æ¶¨', 'å…¨5èƒœç‡%',
            '3å¹´2å‡æ¶¨', '3å¹´2èƒœç‡%', '3å¹´3å‡æ¶¨', '3å¹´3èƒœç‡%', '3å¹´4å‡æ¶¨', '3å¹´4èƒœç‡%', '3å¹´5å‡æ¶¨', '3å¹´5èƒœç‡%']
    
    res_df = pd.DataFrame(valid_results, columns=cols)
    
    # 4. æ ¸å¿ƒï¼šæ¯”å¯¹æº¢ä»·æ•°æ®å¹¶è¿‡æ»¤
    def check_premium(row):
        code = row['ä»£ç ']
        if code in premium_data:
            p_info = premium_data[code]
            if p_info['æº¢ä»·ç‡_num'] > 2.0: # æº¢ä»·ç†”æ–­é˜ˆå€¼ï¼š2.0%
                return None, None, True # æ ‡è®°ä¸ºè¢«è¿‡æ»¤
            return p_info['æº¢ä»·ç‡'], p_info['ä¼°ç®—å‡€å€¼'], False
        return "æœªçŸ¥", "æœªçŸ¥", False

    res_df[['å®æ—¶æº¢ä»·ç‡', 'å‚è€ƒå‡€å€¼', 'is_filtered']] = res_df.apply(lambda r: pd.Series(check_premium(r)), axis=1)
    
    # å‰”é™¤é«˜æº¢ä»·æ ‡çš„
    final_df = res_df[res_df['is_filtered'] == False].drop(columns=['is_filtered']).copy()
    
    # 5. æ’åºä¸ä»Šæ—¥ä¹‹æ˜Ÿ
    final_df['prio'] = [prios[i] for i in final_df.index]
    final_df['bias_val'] = [biases[i] for i in final_df.index]
    final_df = final_df.sort_values(['prio', 'bias_val'], ascending=[False, True])
    if not final_df.empty:
        final_df.iloc[0, 2] = "ğŸ‘‘ä»Šæ—¥ä¹‹æ˜Ÿ " + final_df.iloc[0, 2]
    
    final_df = final_df.drop(columns=['prio', 'bias_val'])

    # 6. ä¿å­˜
    now = datetime.now()
    month_dir = now.strftime('%Y%m')
    if not os.path.exists(month_dir): os.makedirs(month_dir)
    save_path = os.path.join(month_dir, f"etf_final_strategy_{now.strftime('%Y%m%d_%H%M%S')}.csv")
    final_df.to_csv(save_path, index=False, encoding='utf_8_sig')
    print(f"è¿‡æ»¤é«˜æº¢ä»·åï¼Œå‰©ä½™ {len(final_df)} åªæ ‡çš„ã€‚ç»“æœå­˜è‡³: {save_path}")

if __name__ == '__main__':
    main()
